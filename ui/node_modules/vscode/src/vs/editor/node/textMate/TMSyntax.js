/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/
'use strict';
var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
var __param = (this && this.__param) || function (paramIndex, decorator) {
    return function (target, key) { decorator(target, key, paramIndex); }
};
var nls = require('vs/nls');
var errors_1 = require('vs/base/common/errors');
var paths = require('vs/base/common/paths');
var extensionsRegistry_1 = require('vs/platform/extensions/common/extensionsRegistry');
var modes_1 = require('vs/editor/common/modes');
var TMState_1 = require('vs/editor/common/modes/TMState');
var supports_1 = require('vs/editor/common/modes/supports');
var modeService_1 = require('vs/editor/common/services/modeService');
var vscode_textmate_1 = require('vscode-textmate');
var modeTransition_1 = require('vs/editor/common/core/modeTransition');
var token_1 = require('vs/editor/common/core/token');
// @martin TS(2.0.2) - Type IJsonSchema has no defined property require. Keeping semantic using any cast
var grammarsExtPoint = extensionsRegistry_1.ExtensionsRegistry.registerExtensionPoint('grammars', {
    description: nls.localize('vscode.extension.contributes.grammars', 'Contributes textmate tokenizers.'),
    type: 'array',
    defaultSnippets: [{ body: [{ language: '{{id}}', scopeName: 'source.{{id}}', path: './syntaxes/{{id}}.tmLanguage.' }] }],
    items: {
        type: 'object',
        defaultSnippets: [{ body: { language: '{{id}}', scopeName: 'source.{{id}}', path: './syntaxes/{{id}}.tmLanguage.' } }],
        properties: {
            language: {
                description: nls.localize('vscode.extension.contributes.grammars.language', 'Language identifier for which this syntax is contributed to.'),
                type: 'string'
            },
            scopeName: {
                description: nls.localize('vscode.extension.contributes.grammars.scopeName', 'Textmate scope name used by the tmLanguage file.'),
                type: 'string'
            },
            path: {
                description: nls.localize('vscode.extension.contributes.grammars.path', 'Path of the tmLanguage file. The path is relative to the extension folder and typically starts with \'./syntaxes/\'.'),
                type: 'string'
            },
            injectTo: {
                description: nls.localize('vscode.extension.contributes.grammars.injectTo', 'List of language scope names to which this grammar is injected to.'),
                type: 'array',
                items: {
                    type: 'string'
                }
            }
        },
        require: ['scopeName', 'path']
    }
});
var MainProcessTextMateSyntax = (function () {
    function MainProcessTextMateSyntax(modeService) {
        var _this = this;
        this._modeService = modeService;
        this._scopeNameToFilePath = {};
        this._injections = {};
        this._grammarRegistry = new vscode_textmate_1.Registry({
            getFilePath: function (scopeName) {
                return _this._scopeNameToFilePath[scopeName];
            },
            getInjections: function (scopeName) {
                return _this._injections[scopeName];
            }
        });
        grammarsExtPoint.setHandler(function (extensions) {
            for (var i = 0; i < extensions.length; i++) {
                var grammars = extensions[i].value;
                for (var j = 0; j < grammars.length; j++) {
                    _this._handleGrammarExtensionPointUser(extensions[i].description.extensionFolderPath, grammars[j], extensions[i].collector);
                }
            }
        });
    }
    MainProcessTextMateSyntax.prototype._handleGrammarExtensionPointUser = function (extensionFolderPath, syntax, collector) {
        var _this = this;
        if (syntax.language && ((typeof syntax.language !== 'string') || !this._modeService.isRegisteredMode(syntax.language))) {
            collector.error(nls.localize('invalid.language', "Unknown language in `contributes.{0}.language`. Provided value: {1}", grammarsExtPoint.name, String(syntax.language)));
            return;
        }
        if (!syntax.scopeName || (typeof syntax.scopeName !== 'string')) {
            collector.error(nls.localize('invalid.scopeName', "Expected string in `contributes.{0}.scopeName`. Provided value: {1}", grammarsExtPoint.name, String(syntax.scopeName)));
            return;
        }
        if (!syntax.path || (typeof syntax.path !== 'string')) {
            collector.error(nls.localize('invalid.path.0', "Expected string in `contributes.{0}.path`. Provided value: {1}", grammarsExtPoint.name, String(syntax.path)));
            return;
        }
        if (syntax.injectTo && (!Array.isArray(syntax.injectTo) || syntax.injectTo.some(function (scope) { return typeof scope !== 'string'; }))) {
            collector.error(nls.localize('invalid.injectTo', "Invalid value in `contributes.{0}.injectTo`. Must be an array of language scope names. Provided value: {1}", grammarsExtPoint.name, JSON.stringify(syntax.injectTo)));
            return;
        }
        var normalizedAbsolutePath = paths.normalize(paths.join(extensionFolderPath, syntax.path));
        if (normalizedAbsolutePath.indexOf(extensionFolderPath) !== 0) {
            collector.warn(nls.localize('invalid.path.1', "Expected `contributes.{0}.path` ({1}) to be included inside extension's folder ({2}). This might make the extension non-portable.", grammarsExtPoint.name, normalizedAbsolutePath, extensionFolderPath));
        }
        this._scopeNameToFilePath[syntax.scopeName] = normalizedAbsolutePath;
        if (syntax.injectTo) {
            for (var _i = 0, _a = syntax.injectTo; _i < _a.length; _i++) {
                var injectScope = _a[_i];
                var injections = this._injections[injectScope];
                if (!injections) {
                    this._injections[injectScope] = injections = [];
                }
                injections.push(syntax.scopeName);
            }
        }
        var modeId = syntax.language;
        if (modeId) {
            var disposable_1 = this._modeService.onDidCreateMode(function (mode) {
                if (mode.getId() !== modeId) {
                    return;
                }
                _this.registerDefinition(modeId, syntax.scopeName);
                disposable_1.dispose();
            });
        }
    };
    MainProcessTextMateSyntax.prototype.registerDefinition = function (modeId, scopeName) {
        this._grammarRegistry.loadGrammar(scopeName, function (err, grammar) {
            if (err) {
                errors_1.onUnexpectedError(err);
                return;
            }
            modes_1.TokenizationRegistry.register(modeId, createTokenizationSupport(modeId, grammar));
        });
    };
    MainProcessTextMateSyntax = __decorate([
        __param(0, modeService_1.IModeService)
    ], MainProcessTextMateSyntax);
    return MainProcessTextMateSyntax;
}());
exports.MainProcessTextMateSyntax = MainProcessTextMateSyntax;
function createTokenizationSupport(modeId, grammar) {
    var tokenizer = new Tokenizer(modeId, grammar);
    return {
        getInitialState: function () { return new TMState_1.TMState(modeId, null, null); },
        tokenize: function (line, state, offsetDelta, stopAtOffset) { return tokenizer.tokenize(line, state, offsetDelta, stopAtOffset); }
    };
}
var DecodeMap = (function () {
    function DecodeMap() {
        this.lastAssignedId = 0;
        this.scopeToTokenIds = Object.create(null);
        this.tokenToTokenId = Object.create(null);
        this.tokenIdToToken = [null];
        this.prevToken = new TMTokenDecodeData([], []);
    }
    DecodeMap.prototype.getTokenIds = function (scope) {
        var tokens = this.scopeToTokenIds[scope];
        if (tokens) {
            return tokens;
        }
        var tmpTokens = scope.split('.');
        tokens = [];
        for (var i = 0; i < tmpTokens.length; i++) {
            var token = tmpTokens[i];
            var tokenId = this.tokenToTokenId[token];
            if (!tokenId) {
                tokenId = (++this.lastAssignedId);
                this.tokenToTokenId[token] = tokenId;
                this.tokenIdToToken[tokenId] = token;
            }
            tokens.push(tokenId);
        }
        this.scopeToTokenIds[scope] = tokens;
        return tokens;
    };
    DecodeMap.prototype.getToken = function (tokenMap) {
        var result = '';
        var isFirst = true;
        for (var i = 1; i <= this.lastAssignedId; i++) {
            if (tokenMap[i]) {
                if (isFirst) {
                    isFirst = false;
                    result += this.tokenIdToToken[i];
                }
                else {
                    result += '.';
                    result += this.tokenIdToToken[i];
                }
            }
        }
        return result;
    };
    return DecodeMap;
}());
exports.DecodeMap = DecodeMap;
var TMTokenDecodeData = (function () {
    function TMTokenDecodeData(scopes, scopeTokensMaps) {
        this.scopes = scopes;
        this.scopeTokensMaps = scopeTokensMaps;
    }
    return TMTokenDecodeData;
}());
exports.TMTokenDecodeData = TMTokenDecodeData;
function depth(stackElement) {
    var result = 0;
    while (stackElement) {
        result++;
        stackElement = stackElement._parent;
    }
    return result;
}
var Tokenizer = (function () {
    function Tokenizer(modeId, grammar) {
        this._modeId = modeId;
        this._grammar = grammar;
        this._decodeMap = new DecodeMap();
    }
    Tokenizer.prototype.tokenize = function (line, state, offsetDelta, stopAtOffset) {
        if (offsetDelta === void 0) { offsetDelta = 0; }
        // Do not attempt to tokenize if a line has over 20k
        // or if the rule stack contains more than 100 rules (indicator of broken grammar that forgets to pop rules)
        if (line.length >= 20000 || depth(state.getRuleStack()) > 100) {
            return new supports_1.LineTokens([new token_1.Token(offsetDelta, '')], [new modeTransition_1.ModeTransition(offsetDelta, state.getModeId())], offsetDelta, state);
        }
        var freshState = state.clone();
        var textMateResult = this._grammar.tokenizeLine(line, freshState.getRuleStack());
        freshState.setRuleStack(textMateResult.ruleStack);
        // Create the result early and fill in the tokens later
        var tokens = [];
        var lastTokenType = null;
        for (var tokenIndex = 0, len = textMateResult.tokens.length; tokenIndex < len; tokenIndex++) {
            var token = textMateResult.tokens[tokenIndex];
            var tokenStartIndex = token.startIndex;
            var tokenType = decodeTextMateToken(this._decodeMap, token.scopes);
            // do not push a new token if the type is exactly the same (also helps with ligatures)
            if (tokenType !== lastTokenType) {
                tokens.push(new token_1.Token(tokenStartIndex + offsetDelta, tokenType));
                lastTokenType = tokenType;
            }
        }
        return new supports_1.LineTokens(tokens, [new modeTransition_1.ModeTransition(offsetDelta, freshState.getModeId())], offsetDelta + line.length, freshState);
    };
    return Tokenizer;
}());
function decodeTextMateToken(decodeMap, scopes) {
    var prevTokenScopes = decodeMap.prevToken.scopes;
    var prevTokenScopesLength = prevTokenScopes.length;
    var prevTokenScopeTokensMaps = decodeMap.prevToken.scopeTokensMaps;
    var scopeTokensMaps = [];
    var prevScopeTokensMaps = [];
    var sameAsPrev = true;
    for (var level = 1; level < scopes.length; level++) {
        var scope = scopes[level];
        if (sameAsPrev) {
            if (level < prevTokenScopesLength && prevTokenScopes[level] === scope) {
                prevScopeTokensMaps = prevTokenScopeTokensMaps[level];
                scopeTokensMaps[level] = prevScopeTokensMaps;
                continue;
            }
            sameAsPrev = false;
        }
        var tokens = decodeMap.getTokenIds(scope);
        prevScopeTokensMaps = prevScopeTokensMaps.slice(0);
        for (var i = 0; i < tokens.length; i++) {
            prevScopeTokensMaps[tokens[i]] = true;
        }
        scopeTokensMaps[level] = prevScopeTokensMaps;
    }
    decodeMap.prevToken = new TMTokenDecodeData(scopes, scopeTokensMaps);
    return decodeMap.getToken(prevScopeTokensMaps);
}
exports.decodeTextMateToken = decodeTextMateToken;
